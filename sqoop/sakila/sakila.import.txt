## import all payments from sakila database to hdfs
sqoop-import --connect jdbc:mysql://quickstart.cloudera:3306/sakila --username root  --target-dir /user/cloudera/output/handson_train/may/sqoop/import/payments_parquet  --as-parquetfile --password-file /user/cloudera/passwordfile --query "SELECT p.payment_id, p.rental_id, p.amount, p.payment_date, p.last_update, c.customer_id, concat(c.first_name, ' ', c.last_name) customer_name, s.staff_id, concat(s.first_name, ' ', s.last_name) staff_name, r.rental_date, r.return_date, f.title film_title, f.description film_desc, f.release_year file_release_year FROM payment p  join customer c on c.customer_id = p.customer_id join staff s on s.staff_id = p.staff_id left join rental r on r.rental_id = p.rental_id left join inventory inv on r.inventory_id = inv.inventory_id left join film f on inv.film_id = f.film_id WHERE \$CONDITIONS" --mapreduce-job-name denor-payment-query -m 2 --split-by payment_id

## import all films (denormalized) from sakila db to hdfs compressing the output
sqoop-import --connect jdbc:mysql://quickstart:3306/sakila --username root \
--table v_film --target-dir /user/cloudera/output/handson_train/feb/sqoop/sakila/film  --compress --as-avrodatafile --mapreduce-job-name 'denormalized_film_import' \
-m 2 --split-by film_id --password-file /user/cloudera/passwordfile

## import all films from sakila db to hdfs compressing the output using bzip2 code
sqoop-import --connect jdbc:mysql://iop-bi-master.imdemocloud.com:3306/sakila --username root \
--table v_film --target-dir /user/okmich20/output/handsontrain/sqoop/sakila/film_bzip  --compress \
--compression-codec bzip2 -m 1 --split-by film_id -P
